deepdive {
  
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  # Pipelines
  pipeline.run: "nonlp"
  pipeline.pipelines.nonlp: ["ext_schol"]

  # Put your variables here
  schema.variables {
  
  }

  # Put your extractors here
  extraction.extractors {

    
    ext_schol.input: "SELECT * FROM scholarships"
    ext_schol.output_relation: "schol_mentions"
    ext_schol.udf: ${APP_HOME}"/scripts/get_json_from_deepdive.py"
    ext_schol.before: ${APP_HOME}"/udf/before_schol.sh"
  }

  # Put your inference rules here
  inference.factors {
    
  } 

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.00

}

#ext_sentences.input: """SELECT id as "schol_id", text as "schol_text" FROM scholarships order by id asc"""
    #ext_sentences.output_relation: "schol_sentences"
    #ext_sentences.udf: ${APP_HOME}"/udf/nlp_extractor/run.sh -k schol_id -v schol_text -l 20"
    #ext_sentences.before: ${APP_HOME}"/udf/before_schol_sentences.sh"

    #ext_sentences.input: """SELECT id as "web_id", text as "web_text" FROM websites order by id asc"""
    #ext_sentences.output_relation: "web_sentences"
    #ext_sentences.udf: ${APP_HOME}"/udf/nlp_extractor/run.sh -k web_id -v web_text -l 20"
    #ext_sentences.before: ${APP_HOME}"/udf/before_web_sentences.sh"

    #############################################

